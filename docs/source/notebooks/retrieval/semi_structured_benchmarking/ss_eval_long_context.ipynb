{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82409c3a-5172-429d-9411-cad25079e1de",
   "metadata": {},
   "source": [
    "# Semi-structured eval: Long-context\n",
    "\n",
    "We will test retrival of table information from the `Semi-structured Reports` dataset using various methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b9e4f-f15d-4283-84a7-d4ca0b7f6739",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain langsmith langchain_benchmarks\n",
    "%pip install -U anthropic openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dcbfd5-5f0e-469d-b2b1-79b9c440306b",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0350e25a-c5b0-4b67-8257-6037ecc232df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_benchmarks import registry\n",
    "from langchain_benchmarks.rag.tasks.semi_structured_reports import get_file_names\n",
    "\n",
    "# Task\n",
    "task = registry[\"Semi-structured Reports\"]\n",
    "\n",
    "# Files used\n",
    "paths = list(get_file_names())\n",
    "files = [str(p) for p in paths]\n",
    "\n",
    "### TODO: Replace when dataset is updated\n",
    "dir = \"/Users/rlm/Desktop/Eval_Sets/semi_structured_reports/\"\n",
    "files = [dir + f for f in os.listdir(dir) if f.endswith(\".pdf\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723aa13-abeb-4839-8425-3591ad635893",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3122719-82b4-47ef-9dc8-3df9b73bec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "texts = []\n",
    "for fi in files:\n",
    "    loader = PyPDFLoader(fi)\n",
    "    pdf_pages = loader.load()\n",
    "    texts.extend(pdf_pages)\n",
    "\n",
    "texts = [t.page_content for t in texts]\n",
    "text_string = \" /// New Document /// \".join(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6292b1-5aab-46bb-b03f-79087444835c",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa1e5b2f-6dda-42a0-95a7-bcfd1281c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "\n",
    "def create_chain(model):\n",
    "    # Prompt template\n",
    "    template = \"\"\"Answer the question based only on the following context, which can include text and tables:\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    chain = (\n",
    "        {\n",
    "            \"context\": lambda x: text_string,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return chain\n",
    "\n",
    "\n",
    "# OAI 128k\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4-1106-preview\")\n",
    "chain_oai_128k = create_chain(model)\n",
    "\n",
    "# Anthropic 100k\n",
    "model = ChatAnthropic(temperature=0, model=\"claude-2\")\n",
    "chain_claude = create_chain(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791c28f8-56ea-47db-8417-596fffadd43d",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900dada1-59d1-4a00-80f5-efe2387cef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'oai_128k_d364769e-4327-4f73-be4a-010495456c34' at:\n",
      "https://smith.langchain.com/o/1fa8b1f4-fcb9-4072-9aa9-983e35ad61b8/projects/p/21333311-270b-44fa-83b6-608c89eb962b?eval=true\n",
      "\n",
      "View all tests for Dataset Semi-Structured-Eval-v5 at:\n",
      "https://smith.langchain.com/o/1fa8b1f4-fcb9-4072-9aa9-983e35ad61b8/datasets/2759f13d-c0c0-4d60-a8cf-0ce204750642\n",
      "[------------------------------------------------->] 25/25\n",
      " Eval quantiles:\n",
      "                                          inputs.question  \\\n",
      "count                                                  25   \n",
      "unique                                                 25   \n",
      "top     What is Datadog's Non-GAAP gross margin for th...   \n",
      "freq                                                    1   \n",
      "mean                                                  NaN   \n",
      "std                                                   NaN   \n",
      "min                                                   NaN   \n",
      "25%                                                   NaN   \n",
      "50%                                                   NaN   \n",
      "75%                                                   NaN   \n",
      "max                                                   NaN   \n",
      "\n",
      "        feedback.COT Contextual Accuracy error  execution_time  \n",
      "count                          25.000000     0       25.000000  \n",
      "unique                               NaN     0             NaN  \n",
      "top                                  NaN   NaN             NaN  \n",
      "freq                                 NaN   NaN             NaN  \n",
      "mean                            0.680000   NaN       13.062668  \n",
      "std                             0.476095   NaN        4.990509  \n",
      "min                             0.000000   NaN        6.962163  \n",
      "25%                             0.000000   NaN        9.061899  \n",
      "50%                             1.000000   NaN       12.088541  \n",
      "75%                             1.000000   NaN       14.242016  \n",
      "max                             1.000000   NaN       25.067926  \n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langchain.smith import RunEvalConfig\n",
    "from langsmith.client import Client\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    evaluators=[\"cot_qa\"],\n",
    ")\n",
    "\n",
    "\n",
    "def run_eval(chain, eval_run_name):\n",
    "    \"\"\"\n",
    "    Run eval\n",
    "    \"\"\"\n",
    "    client = Client()\n",
    "    test_run = client.run_on_dataset(\n",
    "        ### TODO: Replace with public dataset\n",
    "        dataset_name=\"Semi-Structured-Eval-v5\",\n",
    "        llm_or_chain_factory=lambda: (lambda x: x[\"question\"]) | chain,\n",
    "        evaluation=eval_config,\n",
    "        verbose=True,\n",
    "        project_name=eval_run_name,\n",
    "    )\n",
    "\n",
    "\n",
    "# Experiments\n",
    "chain_map = {\n",
    "    \"oai_128k\": chain_oai_128k,\n",
    "    # \"claude2_100k_v2\": chain_claude,\n",
    "}\n",
    "\n",
    "run_id = str(uuid.uuid4())\n",
    "for project_name, chain in chain_map.items():\n",
    "    run_eval(chain, project_name + \"_\" + run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fbc0d5-9436-4526-88b3-1bdb0ab98661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
